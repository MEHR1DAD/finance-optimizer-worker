name: Scrape Vahid (Optimized)

on:
  schedule:
    - cron: '*/5 * * * *' # Every 5 minutes
  workflow_dispatch:

jobs:
  scrape-vahid:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      - name: Checkout Code
        uses: actions/checkout@v4
        with:
          fetch-depth: 1 # Shallow clone for speed

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
          cache: 'pip'

      - name: Install Dependencies
        run: |
          pip install -r backend/requirements.txt

      - name: Run Scraper (Vahid Only)
        env:
          TELEGRAM_API_ID: ${{ secrets.TELEGRAM_API_ID }}
          TELEGRAM_API_HASH: ${{ secrets.TELEGRAM_API_HASH }}
          TELEGRAM_SESSION: ${{ secrets.TELEGRAM_SESSION }}
        run: |
          python3 backend/main.py --channels backend/channels.txt --output news_vahid.json --limit 100 --max-duration 250

      - name: Commit & Push (Force)
        run: |
          git config --global user.name "Vahid Scraper Bot"
          git config --global user.email "bot@vahid.news"
          
          git add news_vahid.json
          git add media/ || echo "No media folder"
          
          # Prune old media (>24h) to keep repo light
          if [ -d "media" ]; then
             echo "ðŸ§¹ Pruning old media..."
             find media -type f -mtime +1 -delete || true
          fi
          
          # Commit if changes exist
          if [ -n "$(git status --porcelain)" ]; then
            git commit -m "ðŸš€ Update Vahid News $(date +'%Y-%m-%d %H:%M')"
            git push
          else
            echo "No changes to commit."
          fi
